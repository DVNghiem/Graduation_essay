{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2718,"status":"ok","timestamp":1653625591771,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"1OijlYWhRJPh","outputId":"d0de2933-6a9c-4435-b281-76ba4df14080"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1653625594317,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"sDR-0hzRRn1M","outputId":"0c7a045e-02d5-401e-bd54-63e95f45a82b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1T-TkLmhLIA8qodciANOIZEcC0W8CsU9V/Khóa luận tốt nghiệp/QA\n"]}],"source":["%cd /content/drive/MyDrive/Khóa luận tốt nghiệp/QA"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"5KXy2n_OOVDq","executionInfo":{"status":"ok","timestamp":1653625619500,"user_tz":-420,"elapsed":25185,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["!pip install genz-tokenize==1.2.7a2 -q \n","!pip install vncorenlp -q \n","!pip install tensorflow-addons -q"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"U-1fDGDWPeAd","executionInfo":{"status":"ok","timestamp":1653625623884,"user_tz":-420,"elapsed":4399,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["import tensorflow as tf\n","from genz_tokenize import Tokenize\n","import numpy as np\n","import pickle\n","import random\n","import math\n","from typing import Dict, List, Optional, Union, Tuple\n","from tqdm import tqdm\n","import tensorflow_addons as tfa\n","from vncorenlp import VnCoreNLP\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"fFgbFFOSp3PR","executionInfo":{"status":"ok","timestamp":1653625689006,"user_tz":-420,"elapsed":65145,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["vncore_jar = '/content/drive/MyDrive/Khóa luận tốt nghiệp/Paragraph_Raking/Tensorflow/VnCoreNLP/VnCoreNLP-1.1.1.jar'\n","vncore = VnCoreNLP(vncore_jar)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ad5tCdx3p3Mz","executionInfo":{"status":"ok","timestamp":1653625689007,"user_tz":-420,"elapsed":40,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["with open('/content/drive/MyDrive/Khóa luận tốt nghiệp/QA/new_data.pkl', 'rb') as f:\n","    context, question, answer = pickle.load(f)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1653625689008,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"90ucPopCac12","outputId":"131023aa-eb91-4da6-ae60-9e3894c111b7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21072"]},"metadata":{},"execution_count":8}],"source":["len(context)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"JzUBWlecp3Jw","executionInfo":{"status":"ok","timestamp":1653625689505,"user_tz":-420,"elapsed":504,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["tokenize = Tokenize()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1653625689505,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"nVkf3KhjsQpp","outputId":"f22b4cb5-cf1d-4fe4-cfaf-fbe5a43b65dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(702, 87)"]},"metadata":{},"execution_count":10}],"source":["maxlen_c = 0\n","maxlen_q = 0\n","for i, j in zip(context, question):\n","    maxlen_c = max(maxlen_c, len(i.split()))\n","    maxlen_q = max(maxlen_q, len(j.split()))\n","maxlen_c, maxlen_q"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1653625689506,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"6EWayOuUxHcF","outputId":"15def505-890d-4985-d50c-7e276939a035"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(21072, 21072)"]},"metadata":{},"execution_count":11}],"source":["dem = 0\n","for i in context:\n","    if len(i.split())<800:\n","        dem+=1\n","dem, len(context)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"8HoFkVbDjtPv","executionInfo":{"status":"ok","timestamp":1653625690847,"user_tz":-420,"elapsed":885,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["context = np.array(context)\n","question = np.array(question)\n","answer = np.array(answer)\n","\n","order = [i for i in range(len(context))]\n","random.shuffle(order)\n","\n","context = context[order]\n","question = question[order]\n","answer = answer[order]"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"C_WxCKdtxrf6","executionInfo":{"status":"ok","timestamp":1653625695480,"user_tz":-420,"elapsed":4638,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["y = []\n","for c, a in zip(context, answer):\n","    start = 0\n","    end = 0\n","    a = a.split()\n","    c = c.split()\n","    for i in range(0, len(c)-len(a)+1, 1):\n","        s = sum([c[i+j] == a[j] for j in range(len(a))])\n","        if s == len(a):\n","            start = i\n","            end = start+len(a)-1\n","            break\n","    y.append([start, end])\n","train_y = np.array(y)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"8qmXsGoGfcp9","executionInfo":{"status":"ok","timestamp":1653625695483,"user_tz":-420,"elapsed":52,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["context_val = context[:2000]\n","context_test = context[2000:3000]\n","context = context[3000:]\n","\n","question_val = question[:2000]\n","question_test = question[2000:3000]\n","question = question[3000:]\n","\n","y_val = y[:2000]\n","y_test = y[2000:3000]\n","y_train = y[3000:]"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52,"status":"ok","timestamp":1653625695485,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"2O2TJu_gV_AT","outputId":"d6726eb4-5161-4aeb-f994-3b50bfa87ab6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((18072,), (18072,), (21072, 2))"]},"metadata":{},"execution_count":15}],"source":["context.shape, question.shape, train_y.shape"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"5FrAdriWZEWD","executionInfo":{"status":"ok","timestamp":1653625695486,"user_tz":-420,"elapsed":44,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["label = ['ai', 'cai gi', 'con vat', 'nhu the nao', 'number', 'tai sao', 'thoi gian', 'time', 'thuc vat', 'yes no', 'location']\n","postag_label = ['B', 'Np', 'Nc', 'Nu', 'N', 'Ny', 'Ni', 'Nb', 'V', 'Vb', 'A', 'Ab', 'P', 'R', 'L', 'M', 'E', 'C', 'Cc', 'I', 'T', 'Y', 'Z', 'X', 'CH']\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"gFgq5F2_p3Hg","executionInfo":{"status":"ok","timestamp":1653625695487,"user_tz":-420,"elapsed":43,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["def int64_feature(value):\n","    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n","\n","def create_example(encode_input_ids, encode_attention_mask, postag, decode_input_ids, decode_attention_mask, y):\n","    feature = {\n","        \"encode_input_ids\": int64_feature(encode_input_ids),\n","        \"encode_attention_mask\": int64_feature(encode_attention_mask),\n","        'postag': int64_feature(postag),\n","        \"decode_input_ids\": int64_feature(decode_input_ids),\n","        \"decode_attention_mask\": int64_feature(decode_attention_mask),\n","        \"y\": int64_feature(y),\n","    }\n","    return tf.train.Example(features=tf.train.Features(feature=feature))\n","\n","def getTypeOfWord(vncore, text):\n","    out = np.zeros(shape=(277, len(postag_label)), dtype = np.int64)\n","    pos = pos_tag(text, vncore)\n","    for i in range(len(pos)):\n","        if i == 277:\n","            print(pos)\n","        index_pos = postag_label.index(pos[i][1])\n","        out[i, index_pos] = 1\n","    return out.reshape(1, -1).tolist()[0]\n","\n","def pos_tag(text, vncore):\n","    text = text.replace('_', ' ')\n","    tag = vncore.pos_tag(text)\n","    combine = []\n","    for i in tag:\n","        combine += i\n","    return combine"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":230190,"status":"ok","timestamp":1652413065474,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"VwatXjpTuZjq","outputId":"9c7a136e-4e1b-4d5c-961c-fae190322b6f"},"outputs":[{"output_type":"stream","name":"stderr","text":["18072it [03:49, 78.60it/s]\n"]}],"source":["with tf.io.TFRecordWriter(\"tfrecord_data/data_train.tfrecord\") as tfrecord_writer:\n","    for e, v, y in tqdm(zip(question, context, y_train)):\n","        x = tokenize(e, max_len = 277, truncation = True, padding = True)\n","        encode_input_ids = x['input_ids']\n","        encode_attention_mask = x['attention_mask']\n","        postag = getTypeOfWord(vncore, e)\n","        x = tokenize(v, max_len = 800, truncation = True, padding = True)\n","        decode_input_ids = x['input_ids']\n","        decode_attention_mask = x['attention_mask']\n","        example = create_example(encode_input_ids, encode_attention_mask, postag, decode_input_ids, decode_attention_mask, y)\n","        tfrecord_writer.write(example.SerializeToString())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23058,"status":"ok","timestamp":1652413088519,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"CdrxtPckWSsD","outputId":"1eef82df-4904-428a-bb5a-58ec66bdeea2"},"outputs":[{"output_type":"stream","name":"stderr","text":["2000it [00:22, 88.82it/s] \n"]}],"source":["with tf.io.TFRecordWriter(\"tfrecord_data/data_val.tfrecord\") as tfrecord_writer:\n","    for e, v, y in tqdm(zip(question_val, context_val, y_val)):\n","        x = tokenize(e, max_len = 277, truncation = True, padding = True)\n","        encode_input_ids = x['input_ids']\n","        encode_attention_mask = x['attention_mask']\n","        postag = getTypeOfWord(vncore, e)\n","        x = tokenize(v, max_len = 800, truncation = True, padding = True)\n","        decode_input_ids = x['input_ids']\n","        decode_attention_mask = x['attention_mask']\n","        example = create_example(encode_input_ids, encode_attention_mask, postag, decode_input_ids, decode_attention_mask, y)\n","        tfrecord_writer.write(example.SerializeToString())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12567,"status":"ok","timestamp":1652413101068,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"3YPUl8lvWpMC","outputId":"1fe92977-0840-40b0-ea06-d93de7a39d5e"},"outputs":[{"output_type":"stream","name":"stderr","text":["1000it [00:11, 90.77it/s]\n"]}],"source":["with tf.io.TFRecordWriter(\"tfrecord_data/data_test.tfrecord\") as tfrecord_writer:\n","    for e, v, y in tqdm(zip(question_test, context_test, y_test)):\n","        x = tokenize(e, max_len = 277, truncation = True, padding = True)\n","        encode_input_ids = x['input_ids']\n","        encode_attention_mask = x['attention_mask']\n","        postag = getTypeOfWord(vncore, e)\n","        x = tokenize(v, max_len = 800, truncation = True, padding = True)\n","        decode_input_ids = x['input_ids']\n","        decode_attention_mask = x['attention_mask']\n","        example = create_example(encode_input_ids, encode_attention_mask, postag, decode_input_ids, decode_attention_mask, y)\n","        tfrecord_writer.write(example.SerializeToString())"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"USk7_F6Q00mT","executionInfo":{"status":"ok","timestamp":1653625695489,"user_tz":-420,"elapsed":44,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["def parse_tfrecord_fn(example):\n","    feature = {\n","        \"encode_input_ids\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","        \"encode_attention_mask\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","        \"postag\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","        \"decode_input_ids\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","        \"decode_attention_mask\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","        \"y\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing = True),\n","    }\n","    example = tf.io.parse_single_example(example, feature)\n","    return example[\"encode_input_ids\"], example[\"encode_attention_mask\"], example[\"postag\"], example[\"decode_input_ids\"], example['decode_attention_mask'], example['y']\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Wdi-y3VF00h7","executionInfo":{"status":"ok","timestamp":1653625696639,"user_tz":-420,"elapsed":1193,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","BATCH_SIZE = 10\n","filenames = tf.io.gfile.glob('tfrecord_data/data_train.tfrecord')\n","ignore_order = tf.data.Options()\n","ignore_order.experimental_deterministic = False\n","dataset_train = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n","dataset_train = dataset_train.with_options(ignore_order)\n","dataset_train = dataset_train.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n","dataset_train = dataset_train.cache()\n","dataset_train = dataset_train.shuffle(BATCH_SIZE * 10).batch(BATCH_SIZE)\n","dataset_train = dataset_train.prefetch(AUTOTUNE)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"6JYkkTgbifjs","executionInfo":{"status":"ok","timestamp":1653625696640,"user_tz":-420,"elapsed":12,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","BATCH_SIZE = 10\n","filenames = tf.io.gfile.glob('tfrecord_data/data_test.tfrecord')\n","ignore_order = tf.data.Options()\n","ignore_order.experimental_deterministic = False\n","dataset_test = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n","dataset_test = dataset_test.with_options(ignore_order)\n","dataset_test = dataset_test.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n","dataset_test = dataset_test.cache()\n","dataset_test = dataset_test.shuffle(BATCH_SIZE * 10).batch(BATCH_SIZE)\n","dataset_test = dataset_test.prefetch(AUTOTUNE)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"UCq6mxyQijTD","executionInfo":{"status":"ok","timestamp":1653625696641,"user_tz":-420,"elapsed":12,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["AUTOTUNE = tf.data.AUTOTUNE\n","BATCH_SIZE = 10\n","filenames = tf.io.gfile.glob('tfrecord_data/data_val.tfrecord')\n","ignore_order = tf.data.Options()\n","ignore_order.experimental_deterministic = False\n","dataset_val = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n","dataset_val = dataset_val.with_options(ignore_order)\n","dataset_val = dataset_val.map(parse_tfrecord_fn, num_parallel_calls=AUTOTUNE)\n","dataset_val = dataset_val.cache()\n","dataset_val = dataset_val.shuffle(BATCH_SIZE * 10).batch(BATCH_SIZE)\n","dataset_val = dataset_val.prefetch(AUTOTUNE)"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653625696641,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"wKjwyPCpDYIb","outputId":"ccb9f86d-dcf9-4671-e8c6-64e35d5b9076"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([10, 277]), TensorShape([10, 6925]), TensorShape([10, 2]))"]},"metadata":{},"execution_count":22}],"source":["for x1, x2, x3, x4, x5, y in dataset_train:\n","    break\n","x1.shape, x3.shape, y.shape"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"5kFRRFoEVbi3","executionInfo":{"status":"ok","timestamp":1653625696642,"user_tz":-420,"elapsed":10,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class Config:\n","    def __init__(\n","        self,\n","        input_vocab_size = 50265,\n","        target_vocab_size = 40000,\n","        max_position_embeddings=258,\n","        hidden_size = 256,\n","        initializer_range = 0.02,\n","        layer_norm_eps = 1e-6,\n","        hidden_dropout_prob = 0.1,\n","        attention_probs_dropout_prob = 0.1,\n","        num_attention_heads = 8,\n","        num_hidden_layers = 8,\n","        is_decoder = True,\n","        intermediate_size = 1024,\n","        type_vocab_size = 1\n","    ):\n","        self.input_vocab_size = input_vocab_size\n","        self.target_vocab_size = target_vocab_size\n","        self.max_position_embeddings = max_position_embeddings\n","        self.hidden_size = hidden_size\n","        self.initializer_range = initializer_range\n","        self.layer_norm_eps = layer_norm_eps\n","        self.hidden_dropout_prob = hidden_dropout_prob\n","        self.num_attention_heads = num_attention_heads\n","        self.num_hidden_layers = num_hidden_layers\n","        self.is_decoder = is_decoder\n","        self.intermediate_size = intermediate_size\n","        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n","        self.type_vocab_size = type_vocab_size\n","        "]},{"cell_type":"code","execution_count":24,"metadata":{"id":"-3eG-qv_a5Ys","executionInfo":{"status":"ok","timestamp":1653625696642,"user_tz":-420,"elapsed":10,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaEmbeddings(tf.keras.layers.Layer):\n","    \"\"\"\n","    Same as BertEmbeddings with a tiny tweak for positional embeddings indexing.\n","    \"\"\"\n","\n","    def __init__(self, config, vocab_size, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.padding_idx = 0\n","        self.vocab_size = vocab_size\n","        self.type_vocab_size = config.type_vocab_size\n","        self.hidden_size = config.hidden_size\n","        self.max_position_embeddings = config.max_position_embeddings\n","        self.initializer_range = config.initializer_range\n","        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n","        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n","\n","    def build(self, input_shape: tf.TensorShape):\n","        with tf.name_scope(\"word_embeddings\"):\n","            self.weight = self.add_weight(\n","                name=\"weight\",\n","                shape=[self.vocab_size, self.hidden_size],\n","                initializer=get_initializer(self.initializer_range),\n","            )\n","\n","        with tf.name_scope(\"token_type_embeddings\"):\n","            self.token_type_embeddings = self.add_weight(\n","                name=\"embeddings\",\n","                shape=[self.type_vocab_size, self.hidden_size],\n","                initializer=get_initializer(self.initializer_range),\n","            )\n","\n","        with tf.name_scope(\"position_embeddings\"):\n","            self.position_embeddings = self.add_weight(\n","                name=\"embeddings\",\n","                shape=[self.max_position_embeddings, self.hidden_size],\n","                initializer=get_initializer(self.initializer_range),\n","            )\n","\n","        super().build(input_shape)\n","\n","    def create_position_ids_from_input_ids(self, input_ids, past_key_values_length=0):\n","        mask = tf.cast(tf.math.not_equal(input_ids, self.padding_idx), dtype=input_ids.dtype)\n","        incremental_indices = (tf.math.cumsum(mask, axis=1) + past_key_values_length) * mask\n","\n","        return incremental_indices + self.padding_idx\n","\n","    def call(\n","        self,\n","        input_ids=None,\n","        position_ids=None,\n","        token_type_ids=None,\n","        inputs_embeds=None,\n","        past_key_values_length=0,\n","        training=False,\n","    ):\n","        \"\"\"\n","        Applies embedding based on inputs tensor.\n","        Returns:\n","            final_embeddings (`tf.Tensor`): output embedding tensor.\n","        \"\"\"\n","        assert not (input_ids is None and inputs_embeds is None)\n","\n","        if input_ids is not None:\n","            inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n","\n","        input_shape = shape_list(inputs_embeds)[:-1]\n","\n","        if token_type_ids is None:\n","            token_type_ids = tf.fill(dims=input_shape, value=0)\n","\n","        if position_ids is None:\n","            if input_ids is not None:\n","                # Create the position ids from the input token ids. Any padded tokens remain padded.\n","                position_ids = self.create_position_ids_from_input_ids(\n","                    input_ids=input_ids, past_key_values_length=past_key_values_length\n","                )\n","            else:\n","                position_ids = tf.expand_dims(\n","                    tf.range(start=self.padding_idx + 1, limit=input_shape[-1] + self.padding_idx + 1), axis=0\n","                )\n","\n","        position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\n","        token_type_embeds = tf.gather(params=self.token_type_embeddings, indices=token_type_ids)\n","        final_embeddings = inputs_embeds + position_embeds + token_type_embeds\n","        final_embeddings = self.LayerNorm(inputs=final_embeddings)\n","        final_embeddings = self.dropout(inputs=final_embeddings, training=training)\n","\n","        return final_embeddings"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"3VtjeIDwEdPq","executionInfo":{"status":"ok","timestamp":1653625696643,"user_tz":-420,"elapsed":10,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["def get_initializer(initializer_range: float = 0.02) -> tf.initializers.TruncatedNormal:\n","    return tf.keras.initializers.TruncatedNormal(stddev=initializer_range)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"JN6JAaHBE-Cp","executionInfo":{"status":"ok","timestamp":1653625696643,"user_tz":-420,"elapsed":10,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["def shape_list(tensor: Union[tf.Tensor, np.ndarray]) -> List[int]:\n","    if isinstance(tensor, np.ndarray):\n","        return list(tensor.shape)\n","\n","    dynamic = tf.shape(tensor)\n","\n","    if tensor.shape == tf.TensorShape(None):\n","        return dynamic\n","\n","    static = tensor.shape.as_list()\n","\n","    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"11V7KIcZECJa","executionInfo":{"status":"ok","timestamp":1653625697374,"user_tz":-420,"elapsed":740,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaSelfAttention(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        if config.hidden_size % config.num_attention_heads != 0:\n","            raise ValueError(\n","                f\"The hidden size ({config.hidden_size}) is not a multiple of the number \"\n","                f\"of attention heads ({config.num_attention_heads})\"\n","            )\n","\n","        self.num_attention_heads = config.num_attention_heads\n","        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n","        self.all_head_size = self.num_attention_heads * self.attention_head_size\n","        self.sqrt_att_head_size = math.sqrt(self.attention_head_size)\n","\n","        self.query = tf.keras.layers.Dense(\n","            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"query\"\n","        )\n","        self.key = tf.keras.layers.Dense(\n","            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"key\"\n","        )\n","        self.value = tf.keras.layers.Dense(\n","            units=self.all_head_size, kernel_initializer=get_initializer(config.initializer_range), name=\"value\"\n","        )\n","        self.dropout = tf.keras.layers.Dropout(rate=config.attention_probs_dropout_prob)\n","\n","        self.is_decoder = config.is_decoder\n","\n","    def transpose_for_scores(self, tensor: tf.Tensor, batch_size: int) -> tf.Tensor:\n","        # Reshape from [batch_size, seq_length, all_head_size] to [batch_size, seq_length, num_attention_heads, attention_head_size]\n","        tensor = tf.reshape(tensor=tensor, shape=(batch_size, -1, self.num_attention_heads, self.attention_head_size))\n","\n","        # Transpose the tensor from [batch_size, seq_length, num_attention_heads, attention_head_size] to [batch_size, num_attention_heads, seq_length, attention_head_size]\n","        return tf.transpose(tensor, perm=[0, 2, 1, 3])\n","\n","    def call(\n","        self,\n","        hidden_states: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        encoder_hidden_states: tf.Tensor,\n","        encoder_attention_mask: tf.Tensor,\n","        past_key_value: Tuple[tf.Tensor],\n","        output_attentions: bool,\n","        training: bool = False,\n","    ) -> Tuple[tf.Tensor]:\n","        batch_size = shape_list(hidden_states)[0]\n","        mixed_query_layer = self.query(inputs=hidden_states)\n","\n","        # If this is instantiated as a cross-attention module, the keys\n","        # and values come from an encoder; the attention mask needs to be\n","        # such that the encoder's padding tokens are not attended to.\n","        is_cross_attention = encoder_hidden_states is not None\n","\n","        if is_cross_attention and past_key_value is not None:\n","            # reuse k,v, cross_attentions\n","            key_layer = past_key_value[0]\n","            value_layer = past_key_value[1]\n","            attention_mask = encoder_attention_mask\n","        elif is_cross_attention:\n","            key_layer = self.transpose_for_scores(self.key(inputs=encoder_hidden_states), batch_size)\n","            value_layer = self.transpose_for_scores(self.value(inputs=encoder_hidden_states), batch_size)\n","            attention_mask = encoder_attention_mask\n","        elif past_key_value is not None:\n","            key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size)\n","            value_layer = self.transpose_for_scores(self.value(inputs=hidden_states), batch_size)\n","            key_layer = tf.concat([past_key_value[0], key_layer], axis=2)\n","            value_layer = tf.concat([past_key_value[1], value_layer], axis=2)\n","        else:\n","            key_layer = self.transpose_for_scores(self.key(inputs=hidden_states), batch_size)\n","            value_layer = self.transpose_for_scores(self.value(inputs=hidden_states), batch_size)\n","\n","        query_layer = self.transpose_for_scores(mixed_query_layer, batch_size)\n","\n","        if self.is_decoder:\n","            past_key_value = (key_layer, value_layer)\n","\n","        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n","        # (batch size, num_heads, seq_len_q, seq_len_k)\n","        attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n","        dk = tf.cast(self.sqrt_att_head_size, dtype=attention_scores.dtype)\n","        attention_scores = tf.divide(attention_scores, dk)\n","\n","        if attention_mask is not None:\n","            # Apply the attention mask is (precomputed for all layers in TFRobertaModel call() function)\n","            attention_scores = tf.add(attention_scores, attention_mask)\n","\n","        # Normalize the attention scores to probabilities.\n","        attention_probs = tf.nn.softmax(logits=attention_scores, axis=-1)\n","\n","        # This is actually dropping out entire tokens to attend to, which might\n","        # seem a bit unusual, but is taken from the original Transformer paper.\n","        attention_probs = self.dropout(inputs=attention_probs, training=training)\n","\n","        # Mask heads if we want to\n","        if head_mask is not None:\n","            attention_probs = tf.multiply(attention_probs, head_mask)\n","\n","        attention_output = tf.matmul(attention_probs, value_layer)\n","        attention_output = tf.transpose(attention_output, perm=[0, 2, 1, 3])\n","\n","        # (batch_size, seq_len_q, all_head_size)\n","        attention_output = tf.reshape(tensor=attention_output, shape=(batch_size, -1, self.all_head_size))\n","        outputs = (attention_output, attention_probs) if output_attentions else (attention_output,)\n","\n","        if self.is_decoder:\n","            outputs = outputs + (past_key_value,)\n","        return outputs # tuple"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"aswdx4JMEptm","executionInfo":{"status":"ok","timestamp":1653625697376,"user_tz":-420,"elapsed":20,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaSelfOutput(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.dense = tf.keras.layers.Dense(\n","            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n","        )\n","        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n","        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n","\n","    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n","        hidden_states = self.dense(inputs=hidden_states)\n","        hidden_states = self.dropout(inputs=hidden_states, training=training)\n","        hidden_states = self.LayerNorm(inputs=hidden_states + input_tensor)\n","\n","        return hidden_states"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"ja0n0q3_FE81","executionInfo":{"status":"ok","timestamp":1653625697377,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaAttention(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.self_attention = TFRobertaSelfAttention(config, name=\"self\")\n","        self.dense_output = TFRobertaSelfOutput(config, name=\"output\")\n","\n","    def call(\n","        self,\n","        input_tensor: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        encoder_hidden_states: tf.Tensor,\n","        encoder_attention_mask: tf.Tensor,\n","        past_key_value: Tuple[tf.Tensor],\n","        output_attentions: bool,\n","        training: bool = False,\n","    ) -> Tuple[tf.Tensor]:\n","        self_outputs = self.self_attention(\n","            hidden_states=input_tensor,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_attention_mask,\n","            past_key_value=past_key_value,\n","            output_attentions=output_attentions,\n","            training=training,\n","        )\n","        attention_output = self.dense_output(\n","            hidden_states=self_outputs[0], input_tensor=input_tensor, training=training\n","        )\n","        # add attentions (possibly with past_key_value) if we output them\n","        outputs = (attention_output,) + self_outputs[1:]\n","\n","        return outputs"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"aX6xr60KFMW4","executionInfo":{"status":"ok","timestamp":1653625697378,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaIntermediate(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.dense = tf.keras.layers.Dense(\n","            units=config.intermediate_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n","        )\n","        self.intermediate_act_fn = tf.nn.gelu\n","\n","    def call(self, hidden_states: tf.Tensor) -> tf.Tensor:\n","        hidden_states = self.dense(inputs=hidden_states)\n","        hidden_states = self.intermediate_act_fn(hidden_states)\n","\n","        return hidden_states\n"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"C2_Rk8akFcyU","executionInfo":{"status":"ok","timestamp":1653625697379,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaOutput(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.dense = tf.keras.layers.Dense(\n","            units=config.hidden_size, kernel_initializer=get_initializer(config.initializer_range), name=\"dense\"\n","        )\n","        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=config.layer_norm_eps, name=\"LayerNorm\")\n","        self.dropout = tf.keras.layers.Dropout(rate=config.hidden_dropout_prob)\n","\n","    def call(self, hidden_states: tf.Tensor, input_tensor: tf.Tensor, training: bool = False) -> tf.Tensor:\n","        hidden_states = self.dense(inputs=hidden_states)\n","        hidden_states = self.dropout(inputs=hidden_states, training=training)\n","        hidden_states = self.LayerNorm(inputs=hidden_states + input_tensor)\n","\n","        return hidden_states"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"7A9730agFiRA","executionInfo":{"status":"ok","timestamp":1653625697380,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaEncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.attention = TFRobertaAttention(config, name=\"attention\")\n","        self.intermediate = TFRobertaIntermediate(config, name=\"intermediate\")\n","        self.bert_output = TFRobertaOutput(config, name=\"output\")\n","\n","    def call(\n","        self,\n","        hidden_states: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        past_key_value: Optional[Tuple[tf.Tensor]],\n","        output_attentions: bool,\n","        training: bool = False,\n","    ) -> Tuple[tf.Tensor]:\n","        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n","        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n","        self_attention_outputs = self.attention(\n","            input_tensor=hidden_states,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=None,\n","            encoder_attention_mask=None,\n","            past_key_value=self_attn_past_key_value,\n","            output_attentions=output_attentions,\n","            training=training,\n","        )\n","        attention_output = self_attention_outputs[0]\n","\n","        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n","\n","        intermediate_output = self.intermediate(hidden_states=attention_output)\n","        layer_output = self.bert_output(\n","            hidden_states=intermediate_output, input_tensor=attention_output, training=training\n","        )\n","        outputs = (layer_output,) + outputs  # add attentions if we output them\n","        return outputs"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"DP2nXWo7Fxnr","executionInfo":{"status":"ok","timestamp":1653625697381,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaEncoder(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","        self.config = config\n","        self.layer = [TFRobertaEncoderLayer(config, name=f\"layer_._{i}\") for i in range(config.num_hidden_layers)]\n","        \n","    def call(\n","        self,\n","        hidden_states: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        past_key_values: Optional[Tuple[Tuple[tf.Tensor]]],\n","        training: bool = False,\n","    ) -> tf.Tensor:\n","        attention_mask_shape = shape_list(attention_mask)\n","        extended_attention_mask = tf.reshape(\n","                attention_mask, (attention_mask_shape[0], 1, 1, attention_mask_shape[1])\n","        )\n","        extended_attention_mask = tf.cast(extended_attention_mask, dtype=hidden_states.dtype)\n","        one_cst = tf.constant(1.0, dtype=hidden_states.dtype)\n","        ten_thousand_cst = tf.constant(-10000.0, dtype=hidden_states.dtype)\n","        extended_attention_mask = tf.multiply(tf.subtract(one_cst, extended_attention_mask), ten_thousand_cst)\n","\n","        for i, layer_module in enumerate(self.layer):\n","\n","            past_key_value = past_key_values[i] if past_key_values is not None else None\n","\n","            layer_outputs = layer_module(\n","                hidden_states=hidden_states,\n","                attention_mask=extended_attention_mask,\n","                head_mask=head_mask[i],\n","                past_key_value=past_key_value,\n","                output_attentions=True,\n","                training=training,\n","            )\n","            hidden_states = layer_outputs[0]\n","\n","        return hidden_states"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"paiLj6EpFyRS","executionInfo":{"status":"ok","timestamp":1653625697382,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaDecoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.attention = TFRobertaAttention(config, name=\"attention\")\n","\n","        self.crossattention = TFRobertaAttention(config, name=\"crossattention\")\n","        self.intermediate = TFRobertaIntermediate(config, name=\"intermediate\")\n","        self.bert_output = TFRobertaOutput(config, name=\"output\")\n","\n","    def call(\n","        self,\n","        hidden_states: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        encoder_hidden_states: Optional[tf.Tensor],\n","        encoder_attention_mask: Optional[tf.Tensor],\n","        past_key_value: Optional[Tuple[tf.Tensor]],\n","        output_attentions: bool,\n","        training: bool = False,\n","    ) -> tf.Tensor:\n","        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n","        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n","        \n","        self_attention_outputs = self.attention(\n","            input_tensor=hidden_states,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=None,\n","            encoder_attention_mask=None,\n","            past_key_value=self_attn_past_key_value,\n","            output_attentions=output_attentions,\n","            training=training,\n","        )\n","        attention_output = self_attention_outputs[0]\n","\n","        # if decoder, the last output is tuple of self-attn cache\n","        outputs = self_attention_outputs[1:-1]\n","        present_key_value = self_attention_outputs[-1]\n","\n","        cross_attn_present_key_value = None\n","        # cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple\n","        cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n","        cross_attention_outputs = self.crossattention(\n","            input_tensor=attention_output,\n","            attention_mask=attention_mask,\n","            head_mask=head_mask,\n","            encoder_hidden_states=encoder_hidden_states,\n","            encoder_attention_mask=encoder_attention_mask,\n","            past_key_value=cross_attn_past_key_value,\n","            output_attentions=output_attentions,\n","            training=training,\n","        )\n","        attention_output = cross_attention_outputs[0]\n","        outputs = outputs + cross_attention_outputs[1:-1]  # add cross attentions if we output attention weights\n","\n","        # add cross-attn cache to positions 3,4 of present_key_value tuple\n","        cross_attn_present_key_value = cross_attention_outputs[-1]\n","        present_key_value = present_key_value + cross_attn_present_key_value\n","\n","        intermediate_output = self.intermediate(hidden_states=attention_output)\n","        layer_output = self.bert_output(\n","            hidden_states=intermediate_output, input_tensor=attention_output, training=training\n","        )\n","        outputs = (layer_output,) + outputs  # add attentions if we output them\n","\n","        # if decoder, return the attn key/values as the last output\n","        outputs = outputs + (present_key_value,)\n","        return outputs"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"-bIYJBC5Q2J2","executionInfo":{"status":"ok","timestamp":1653625697383,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaDecoder(tf.keras.layers.Layer):\n","    def __init__(self, config, **kwargs):\n","        super().__init__(**kwargs)\n","        self.config = config\n","        self.layer = [TFRobertaDecoderLayer(config, name=f\"layer_._{i}\") for i in range(config.num_hidden_layers)]\n","\n","    def call(\n","        self,\n","        hidden_states: tf.Tensor,\n","        attention_mask: tf.Tensor,\n","        head_mask: tf.Tensor,\n","        encoder_hidden_states: Optional[tf.Tensor],\n","        encoder_attention_mask: Optional[tf.Tensor],\n","        past_key_values: Optional[Tuple[Tuple[tf.Tensor]]],\n","        training: bool = False,\n","    ) -> tf.Tensor:\n","        attention_mask_shape = shape_list(attention_mask)\n","        input_shape = shape_list(hidden_states)\n","        batch_size, seq_length, _ = input_shape\n","        mask_seq_length = seq_length\n","        seq_ids = tf.range(mask_seq_length)\n","\n","        causal_mask = tf.less_equal(\n","                tf.tile(seq_ids[None, None, :], (batch_size, mask_seq_length, 1)),\n","                seq_ids[None, :, None],\n","        )\n","\n","        causal_mask = tf.cast(causal_mask, dtype=attention_mask.dtype)\n","        extended_attention_mask = causal_mask * attention_mask[:, None, :]\n","        attention_mask_shape = shape_list(extended_attention_mask)\n","        extended_attention_mask = tf.reshape(\n","            extended_attention_mask, (attention_mask_shape[0], 1, attention_mask_shape[1], attention_mask_shape[2])\n","        )\n","\n","        extended_attention_mask = tf.cast(extended_attention_mask, dtype=hidden_states.dtype)\n","        one_cst = tf.constant(1.0, dtype=hidden_states.dtype)\n","        ten_thousand_cst = tf.constant(-10000.0, dtype=hidden_states.dtype)\n","        extended_attention_mask = tf.multiply(tf.subtract(one_cst, extended_attention_mask), ten_thousand_cst)\n","\n","        encoder_attention_mask = tf.cast(encoder_attention_mask, dtype=extended_attention_mask.dtype)\n","        encoder_extended_attention_mask = encoder_attention_mask[:, None, None, :]\n","        \n","        encoder_extended_attention_mask = (1.0 - encoder_extended_attention_mask) * -10000.0\n","        \n","        for i, layer_module in enumerate(self.layer):\n","\n","            past_key_value = past_key_values[i] if past_key_values is not None else None\n","\n","            layer_outputs = layer_module(\n","                hidden_states=hidden_states,\n","                attention_mask=extended_attention_mask,\n","                head_mask=head_mask[i],\n","                encoder_hidden_states=encoder_hidden_states,\n","                encoder_attention_mask=encoder_extended_attention_mask,\n","                past_key_value=past_key_value,\n","                output_attentions=True,\n","                training=training,\n","            )\n","            hidden_states = layer_outputs[0]\n","        return hidden_states"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1653625697719,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"cN4B3uUyPdS7","outputId":"2117aa3a-4a8e-4aaa-a4f8-59a13df8b4c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Latest checkpoint restored!!!\n","\n"]}],"source":["\n","class Embedding(tf.keras.layers.Layer):\n","    def __init__(self, vocab_size, dim, max_position_embeddings,  **kwargs):\n","        super().__init__(**kwargs)\n","        self.vocab_size = vocab_size\n","        self.dim = dim\n","        self.max_position_embeddings = max_position_embeddings\n","        self.LayerNorm = tf.keras.layers.LayerNormalization(epsilon=1e-12, name=\"LayerNorm\")\n","        self.dropout = tf.keras.layers.Dropout(rate=0.1)\n","\n","    def build(self, input_shape: tf.TensorShape):\n","        with tf.name_scope(\"word_embeddings\"):\n","            self.weight = self.add_weight(\n","                name=\"weight\",\n","                shape=[self.vocab_size, self.dim],\n","            )\n","\n","        with tf.name_scope(\"position_embeddings\"):\n","            self.position_embeddings = self.add_weight(\n","                name=\"embeddings\",\n","                shape=[self.max_position_embeddings, self.dim],\n","            )\n","        super().build(input_shape)\n","\n","    def call(self, input_ids=None):\n","        inputs_embeds = tf.gather(params=self.weight, indices=input_ids)\n","        input_shape = tf.shape(input_ids)\n","        position_ids = tf.expand_dims(tf.range(start=0, limit=input_shape[-1]), axis=0)\n","        position_embeds = tf.gather(params=self.position_embeddings, indices=position_ids)\n","        final_embeddings = inputs_embeds + position_embeds\n","        final_embeddings = self.LayerNorm(inputs=final_embeddings)\n","        final_embeddings = self.dropout(inputs=final_embeddings)\n","        return final_embeddings\n","\n","class FeedFoward(tf.keras.layers.Layer):\n","    def __init__(self, d_model, num_class):\n","        super(FeedFoward, self).__init__()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.fc1 = tf.keras.layers.Dense(d_model)\n","        self.dropout = tf.keras.layers.Dropout(0.2)\n","        self.out = tf.keras.layers.Dense(num_class, activation = 'softmax')\n","    \n","    def call(self, inputs):\n","        inputs = self.flatten(inputs)\n","        x = self.fc1(inputs)\n","        x = self.dropout(x)\n","        return self.out(x)\n","class ClassifyModel(tf.keras.Model):\n","    def __init__(self, vocab_size,max_position_embeddings, d_model, num_heads, num_class):\n","        super(ClassifyModel, self).__init__()\n","        self.embedding = Embedding(vocab_size, d_model, max_position_embeddings)\n","        self.layernorm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.mha = tf.keras.layers.MultiHeadAttention(num_heads, d_model, dropout = 0.1)\n","        self.fc = tf.keras.layers.Dense(1)\n","        self.fw = FeedFoward(d_model, num_class)\n","    def call(self, inputs):\n","        x = self.embedding(inputs)\n","        mask = self.mask(inputs)\n","        out_mha = self.mha(x, x, x)\n","        x = self.fc(self.layernorm(x+out_mha))\n","        return self.fw(x)\n","\n","    def mask(self, inputs):\n","        masks = tf.logical_not(tf.math.equal(inputs, 0))\n","        masks = tf.cast(masks, dtype = tf.float32)\n","        return masks[:, tf.newaxis, tf.newaxis, :]\n","\n","model_cls = ClassifyModel(tokenize.vocab_size(), 1000, 256, 3, len(label))\n","\n","def fullConnected(d_model):\n","    model = tf.keras.Sequential()\n","    model.add(tf.keras.layers.Dense(d_model*2, activation='gelu'))\n","    model.add(tf.keras.layers.Dense(d_model, activation = 'sigmoid'))\n","    return model\n","\n","class QuestionAnalys(tf.keras.Model):\n","    def __init__(self, d_model, maxlen, model_cls, num_heads):\n","        super(QuestionAnalys, self).__init__()\n","        self.model_cls = model_cls\n","        self.model_cls.trainable = False\n","\n","        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads, d_model)\n","        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads, d_model)\n","\n","        self.layerNorm1 = tf.keras.layers.LayerNormalization()\n","        self.layerNorm2 = tf.keras.layers.LayerNormalization()\n","\n","        self.fc1 = fullConnected(d_model)\n","        self.fc2 = fullConnected(d_model)\n","        self.fc3 = fullConnected(d_model)\n","\n","        self.fc_postag = tf.keras.layers.Dense(d_model)\n","        self.fc_type = tf.keras.layers.Dense(d_model)\n","\n","        self.out1 = tf.keras.layers.Dense(1, activation = 'gelu')\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.out2 = tf.keras.layers.Dense(d_model, activation = 'gelu')\n","        self.out3 = tf.keras.layers.Dense(maxlen)\n","\n","        self.dropout1 = tf.keras.layers.Dropout(0.2)\n","        self.dropout2= tf.keras.layers.Dropout(0.2)\n","\n","    def mask(self, inputs):\n","        masks = tf.logical_not(tf.math.equal(inputs, 0))\n","        masks = tf.cast(masks, dtype = tf.float32)\n","        return masks[:, tf.newaxis, tf.newaxis, :]\n","    \n","    def call(self, x):\n","        inputs, input_postag = x\n","        emb = self.model_cls.embedding(inputs)\n","        mask = self.mask(inputs)\n","        out_mha = self.mha1(emb, emb, emb, attention_mask = mask)\n","        norm = self.layerNorm1(out_mha+emb)\n","        ff = self.fc1(self.dropout1(norm))\n","\n","        postag = self.fc_postag(input_postag)\n","        out_mha = self.mha2(ff, postag, ff, attention_mask = mask)\n","        norm = self.layerNorm2(ff+out_mha)\n","        ff = self.fc2(self.dropout2(norm))\n","\n","        inputs = tf.cast(inputs, dtype = tf.int32)\n","        out_type = tf.expand_dims(self.fc_type(self.model_cls(inputs)), axis = 1)\n","        out = tf.concat([ff, out_type], axis = 1)\n","        out = self.fc3(out)\n","        out = self.out1(out)\n","        out = self.flatten(out)\n","        out = self.out2(out)\n","        out = self.out3(out)\n","        return out\n","    \n","    def compile(self, loss, optimizer):\n","        super(QuestionAnalys, self).compile()\n","        self.optimizer = optimizer\n","        self.loss = loss\n","        self.train_loss = tf.keras.metrics.Mean()\n","        self.test_loss = tf.keras.metrics.Mean()\n","        \n","    @property\n","    def metrics(self):\n","        return [self.train_loss, self.test_loss]\n","\n","    def train_step(self, data):\n","        x1, x2, y = data\n","        with tf.GradientTape() as tape:\n","            predicts = self([x1, x2])\n","            l = self.loss(y, predicts)\n","        gradient = tape.gradient(l, self.trainable_variables)\n","        self.optimizer.apply_gradients(zip(gradient, self.trainable_variables))\n","        self.train_loss(l)\n","        return {'loss': self.train_loss.result()}\n","        \n","    def test_step(self, data):\n","        x1, x2, y = data\n","        predicts = self([x1, x2])\n","        l = self.loss(y, predicts)\n","        self.test_loss(l)\n","        return {'loss': self.test_loss.result()}\n","\n","d_model = 256\n","num_heads = 6\n","model_analys = QuestionAnalys(d_model, 277, model_cls, num_heads)\n","model_analys.trainable = False\n","checkpoint = tf.train.Checkpoint(\n","        model=model_analys)\n","ckpt_manager = tf.train.CheckpointManager(\n","    checkpoint, '/content/drive/MyDrive/Khóa luận tốt nghiệp/weight_of_word/chekcpoint3', max_to_keep=5)\n","if ckpt_manager.latest_checkpoint:\n","    checkpoint.restore(ckpt_manager.latest_checkpoint)\n","    print('\\nLatest checkpoint restored!!!\\n')\n"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"-pEGneZYUaNY","executionInfo":{"status":"ok","timestamp":1653625697721,"user_tz":-420,"elapsed":7,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["class TFRobertaModel(tf.keras.Model):\n","    def __init__(self, config, model_weight, maxlen_c, **kwargs):\n","        super().__init__(**kwargs)\n","        self.config = config\n","        self.model_weight = model_weight\n","        self.model_weight.trainable = False\n","        self.embedding_decoder = TFRobertaEmbeddings(config, config.target_vocab_size, name = 'embedding_decoder')\n","        self.encoder = TFRobertaEncoder(config, name = 'encoder')\n","        self.decoder = TFRobertaDecoder(config, name = 'decoder')\n","\n","        self.logit = tf.keras.layers.Dense(2)\n","        self.start = tf.keras.layers.Dense(maxlen_c)\n","        self.end = tf.keras.layers.Dense(maxlen_c)\n","    \n","    def call(self, \n","            encoder_inputs: Optional[tf.Tensor],\n","            encoder_attention_mask: Optional[tf.Tensor],\n","            postag: Optional[tf.Tensor],\n","            encoder_token_type_id: tf.Tensor,\n","            head_mask: tf.Tensor,\n","            decoder_inputs: tf.Tensor,\n","            decoder_attention_mask: tf.Tensor,\n","            decoder_token_type_id: tf.Tensor,\n","            training: bool = False):\n","        if head_mask is None:\n","            head_mask = [None] * self.config.num_hidden_layers\n","        if encoder_token_type_id is None:\n","            input_shape = shape_list(encoder_inputs)\n","            encoder_token_type_id = tf.fill(dims=input_shape, value=0)\n","        \n","        # input_ww = tf.pad(encoder_inputs, [[0, 0], [0, 177]], 'CONSTANT', constant_values=0)\n","        ww = self.model_weight([encoder_inputs, postag])\n","        ww = tf.expand_dims(ww, axis = -1)\n","        ww = tf.repeat(ww, self.config.hidden_size, axis=-1)\n","        hidden_states = self.model_weight.model_cls.embedding(encoder_inputs)*ww\n","        encoder_output = self.encoder(\n","                                    hidden_states = hidden_states,\n","                                    attention_mask = encoder_attention_mask,\n","                                    head_mask = head_mask,\n","                                    past_key_values = None,\n","                                    training = training\n","                        )\n","\n","        if decoder_token_type_id is None:\n","            input_shape = shape_list(decoder_inputs)\n","            decoder_token_type_id = tf.fill(dims=input_shape, value=0)\n","        hidden_states = self.embedding_decoder(input_ids = decoder_inputs, token_type_ids = decoder_token_type_id)\n","        decoder_output = self.decoder(\n","            hidden_states = hidden_states,\n","            attention_mask = decoder_attention_mask,\n","            head_mask = head_mask,\n","            encoder_hidden_states = encoder_output,\n","            encoder_attention_mask = encoder_attention_mask,\n","            past_key_values = None,\n","            training = training,\n","        )\n","\n","        logits = self.logit(decoder_output)\n","        start_logits, end_logits = tf.split(value=logits, num_or_size_splits=2, axis=-1)\n","        start_logits = self.start(tf.squeeze(input=start_logits, axis=-1))\n","        end_logits = self.end(tf.squeeze(input=end_logits, axis=-1))\n","        return start_logits, end_logits"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"BcmzHyl3Xpm0","executionInfo":{"status":"ok","timestamp":1653625698157,"user_tz":-420,"elapsed":443,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["config = Config()\n","config.input_vocab_size = tokenize.vocab_size()\n","config.target_vocab_size = tokenize.vocab_size()\n","model = TFRobertaModel(config, model_analys, maxlen_c)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2004,"status":"ok","timestamp":1653625700157,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"seWgJ4KaYDJT","outputId":"2ca5bfb6-0b57-478d-cda8-d6c54745a027"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([10, 702])"]},"metadata":{},"execution_count":39}],"source":["x3 = tf.reshape(x3, (-1, 277, len(postag_label)))\n","model(\n","    encoder_inputs = x1,\n","    encoder_attention_mask = x2,\n","    postag = x3,\n","    encoder_token_type_id = None,\n","    head_mask = None,\n","    decoder_inputs = x4,\n","    decoder_attention_mask = x5,\n","    decoder_token_type_id = None,\n",")[0].shape"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32,"status":"ok","timestamp":1653625700158,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"},"user_tz":-420},"id":"MLq3oGexYiiK","outputId":"54afde50-557b-409b-98ff-1ada7b66c279"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"tf_roberta_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," question_analys (QuestionAn  multiple                 17614370  \n"," alys)                                                           \n","                                                                 \n"," embedding_decoder (TFRobert  multiple                 12463104  \n"," aEmbeddings)                                                    \n","                                                                 \n"," encoder (TFRobertaEncoder)  multiple                  6318080   \n","                                                                 \n"," decoder (TFRobertaDecoder)  multiple                  8427520   \n","                                                                 \n"," dense_14 (Dense)            multiple                  514       \n","                                                                 \n"," dense_15 (Dense)            multiple                  562302    \n","                                                                 \n"," dense_16 (Dense)            multiple                  562302    \n","                                                                 \n","=================================================================\n","Total params: 45,948,192\n","Trainable params: 28,333,822\n","Non-trainable params: 17,614,370\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"f985s3X-lIE2","executionInfo":{"status":"ok","timestamp":1653625700159,"user_tz":-420,"elapsed":17,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n","train_loss = tf.keras.metrics.Mean()\n","train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","def hf_compute_loss(labels, logits):\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n","    )\n","    start_loss = loss_fn(labels[:, 0], logits[0])\n","    end_loss = loss_fn(labels[:, 1], logits[1])\n","\n","    return (start_loss + end_loss) / 2.0\n"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"Dng5iO6akiw_","executionInfo":{"status":"ok","timestamp":1653625700160,"user_tz":-420,"elapsed":17,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["checkpoint_path = \"/content/drive/MyDrive/Khóa luận tốt nghiệp/QA/roberta_weight-final-20\"\n","\n","ckpt1 = tf.train.Checkpoint(model=model,\n","                          optimizer=optimizer)\n","ckpt_manager1 = tf.train.CheckpointManager(ckpt1, checkpoint_path, max_to_keep=2)\n","\n","# if ckpt_manager1.latest_checkpoint:\n","#   ckpt1.restore(ckpt_manager1.latest_checkpoint)\n","#   print ('Latest checkpoint restored!!')"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"aR5XVnmkzfGb","executionInfo":{"status":"ok","timestamp":1653625700160,"user_tz":-420,"elapsed":16,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["@tf.function\n","def train_step(x1, x2, x3, x4, x5, y):\n","    x3 = tf.reshape(x3, (-1, 277, len(postag_label)))\n","    with tf.GradientTape() as tape:\n","        logit = model(\n","                    encoder_inputs = x1,\n","                    encoder_attention_mask = x2,\n","                    postag = x3,\n","                    encoder_token_type_id = None,\n","                    head_mask = None,\n","                    decoder_inputs = x4,\n","                    decoder_attention_mask = x5,\n","                    decoder_token_type_id = None,\n","                    training = True\n","                    )\n","        loss = hf_compute_loss(y, logit)\n","        \n","    optimizer.minimize(loss, model.trainable_variables, tape = tape)\n","    train_loss(loss)\n","\n","    train_acc.update_state(y[:, 0:1], logit[0])\n","    train_acc.update_state(y[:, 1:], logit[1])\n"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"EHQv1G2QiwcP","executionInfo":{"status":"ok","timestamp":1653625700161,"user_tz":-420,"elapsed":16,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["@tf.function\n","def test_step(x1, x2, x3, x4, x5, y):\n","    x3 = tf.reshape(x3, (-1, 277, len(postag_label)))\n","    logit = model(\n","                encoder_inputs = x1,\n","                encoder_attention_mask = x2,\n","                postag = x3,\n","                encoder_token_type_id = None,\n","                head_mask = None,\n","                decoder_inputs = x4,\n","                decoder_attention_mask = x5,\n","                decoder_token_type_id = None,\n","                )\n","    loss = hf_compute_loss(y, logit)\n","    train_loss(loss)\n","\n","    train_acc.update_state(y[:, 0:1], logit[0])\n","    train_acc.update_state(y[:, 1:], logit[1])\n"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAVRWySt0oEN","outputId":"fc872259-0cd6-408b-c60e-a8448d04ad50","executionInfo":{"status":"ok","timestamp":1653645441962,"user_tz":-420,"elapsed":19741817,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","epoch 1/20\n","18080/18072 [==============================] - 967s 53ms/step - loss: 3.5960 - acc: 0.3577\n","Epoch 1 val_loss: 2.7998 val_acc: 0.4385\n","\n","epoch 2/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 2.5396 - acc: 0.4805\n","Epoch 2 val_loss: 2.2251 val_acc: 0.5347\n","\n","epoch 3/20\n","18080/18072 [==============================] - 929s 51ms/step - loss: 2.1092 - acc: 0.5410\n","Epoch 3 val_loss: 1.9304 val_acc: 0.5828\n","\n","epoch 4/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.8957 - acc: 0.5772\n","Epoch 4 val_loss: 1.8165 val_acc: 0.5975\n","\n","epoch 5/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.7718 - acc: 0.5998\n","Epoch 5 val_loss: 1.6955 val_acc: 0.6320\n","\n","epoch 6/20\n","18080/18072 [==============================] - 927s 51ms/step - loss: 1.6738 - acc: 0.6187\n","Epoch 6 val_loss: 1.6640 val_acc: 0.6510\n","\n","epoch 7/20\n","18080/18072 [==============================] - 927s 51ms/step - loss: 1.5959 - acc: 0.6367\n","Epoch 7 val_loss: 1.6161 val_acc: 0.6605\n","\n","epoch 8/20\n","18080/18072 [==============================] - 927s 51ms/step - loss: 1.5222 - acc: 0.6506\n","Epoch 8 val_loss: 1.5865 val_acc: 0.6683\n","\n","epoch 9/20\n","18080/18072 [==============================] - 927s 51ms/step - loss: 1.4566 - acc: 0.6647\n","Epoch 9 val_loss: 1.5799 val_acc: 0.6835\n","\n","epoch 10/20\n","18080/18072 [==============================] - 927s 51ms/step - loss: 1.3932 - acc: 0.6790\n","Epoch 10 val_loss: 1.5653 val_acc: 0.6898\n","\n","epoch 11/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.3347 - acc: 0.6912\n","Epoch 11 val_loss: 1.5698 val_acc: 0.6977\n","\n","epoch 12/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.2773 - acc: 0.7039\n","Epoch 12 val_loss: 1.5739 val_acc: 0.7003\n","\n","epoch 13/20\n","18080/18072 [==============================] - 930s 51ms/step - loss: 1.2256 - acc: 0.7160\n","Epoch 13 val_loss: 1.5445 val_acc: 0.7132\n","\n","epoch 14/20\n","18080/18072 [==============================] - 929s 51ms/step - loss: 1.1795 - acc: 0.7250\n","Epoch 14 val_loss: 1.5381 val_acc: 0.7215\n","\n","epoch 15/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.1375 - acc: 0.7337\n","Epoch 15 val_loss: 1.5606 val_acc: 0.7290\n","\n","epoch 16/20\n","18080/18072 [==============================] - 929s 51ms/step - loss: 1.0941 - acc: 0.7434\n","Epoch 16 val_loss: 1.5426 val_acc: 0.7322\n","\n","epoch 17/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 1.0610 - acc: 0.7502\n","Epoch 17 val_loss: 1.5862 val_acc: 0.7362\n","\n","epoch 18/20\n","18080/18072 [==============================] - 930s 51ms/step - loss: 1.0250 - acc: 0.7566\n","Epoch 18 val_loss: 1.5335 val_acc: 0.7380\n","\n","epoch 19/20\n","18080/18072 [==============================] - 930s 51ms/step - loss: 0.9949 - acc: 0.7626\n","Epoch 19 val_loss: 1.5293 val_acc: 0.7458\n","\n","epoch 20/20\n","18080/18072 [==============================] - 928s 51ms/step - loss: 0.9663 - acc: 0.7661\n","Epoch 20 val_loss: 1.5338 val_acc: 0.7450\n"]}],"source":["hist = {\n","    'loss':[],\n","    'acc':[],\n","    'val_loss':[],\n","    'val_acc':[]\n","}\n","epochs = 20\n","for epoch in range(epochs):\n","    train_loss.reset_states()\n","    train_acc.reset_states()\n","    print(\"\\nepoch {}/{}\".format(epoch+1,epochs))\n","    prog = tf.keras.utils.Progbar(len(question), stateful_metrics=['loss', 'acc'])\n","    for batch, (x1, x2, x3, x4, x5, y) in enumerate(dataset_train):\n","        train_step(x1, x2, x3, x4, x5, y)\n","        values=[('loss', train_loss.result().numpy()),('acc', train_acc.result().numpy())]\n","        prog.add(BATCH_SIZE, values=values)\n","    \n","    hist['loss'].append(train_loss.result().numpy())\n","    hist['acc'].append(train_acc.result().numpy())\n","\n","    train_loss.reset_states()\n","    train_acc.reset_states()\n","\n","    for batch, (x1, x2, x3, x4, x5, y) in enumerate(dataset_val):\n","        test_step(x1, x2, x3, x4, x5, y)\n","\n","    hist['val_loss'].append(train_loss.result().numpy())\n","    hist['val_acc'].append(train_acc.result().numpy())\n","    print('Epoch %d val_loss: %.4f val_acc: %.4f'%(epoch+1, train_loss.result().numpy(), train_acc.result().numpy()))\n","\n","    ckpt_manager1.save()\n","    # with open('hist_rb2.pkl', 'wb') as f:\n","    #     pickle.dump(hist, f)\n","  "]},{"cell_type":"code","execution_count":45,"metadata":{"id":"-4PpzG93matJ","executionInfo":{"status":"ok","timestamp":1653645441965,"user_tz":-420,"elapsed":27,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":46,"metadata":{"id":"GJPOD96enaUx","executionInfo":{"status":"ok","timestamp":1653645441966,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["# with open('/content/drive/MyDrive/DoanBert/hist_rb2.pkl', 'rb') as f:\n","#         hist = pickle.load(f)"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"WyR3rH9BnaPs","executionInfo":{"status":"ok","timestamp":1653645441968,"user_tz":-420,"elapsed":20,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":46,"metadata":{"id":"DLUzBfsUnaH7","executionInfo":{"status":"ok","timestamp":1653645441969,"user_tz":-420,"elapsed":20,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["    "]},{"cell_type":"code","execution_count":47,"metadata":{"id":"lk6uKYgSvuMk","executionInfo":{"status":"ok","timestamp":1653645441970,"user_tz":-420,"elapsed":21,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"TaNqDPTt1ExI","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1653645441971,"user_tz":-420,"elapsed":21,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}},"outputId":"1e9955b8-9d85-480a-932d-90ac4c96ab3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(hist['acc'], label = 'acc')\n","plt.plot(hist['val_acc'], label = 'val_acc')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"c5Ju7JKH1IbN","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1653645442511,"user_tz":-420,"elapsed":559,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}},"outputId":"5b37c966-df08-43f5-9f35-c0a21cc7cb2f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.plot(hist['loss'], label = 'loss')\n","plt.plot(hist['val_loss'], label = 'val_loss')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"5rHlz_R-vw0B","executionInfo":{"status":"ok","timestamp":1653645460298,"user_tz":-420,"elapsed":17791,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["# evaluate\n","train_loss.reset_states()\n","train_acc.reset_states()\n","for batch, (x1, x2, x3, x4, x5, y) in enumerate(dataset_test):\n","    test_step(x1, x2, x3, x4, x5, y)"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"0ZlaBPiSecxM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653645460303,"user_tz":-420,"elapsed":88,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}},"outputId":"ee5e565c-d6d2-433c-fd6e-65d8a7aaa9fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["test loss: 1.7152\n","test accuracy: 0.7450\n"]}],"source":["print('test loss: %.4f'%train_loss.result().numpy())\n","print('test accuracy: %.4f'%train_acc.result().numpy())"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"WuhDAZuLekJp","executionInfo":{"status":"ok","timestamp":1653645501250,"user_tz":-420,"elapsed":41019,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["start_pred = []\n","end_pred = []\n","start_true = []\n","end_true = []\n","for x1, x2, x3, x4, x5, y in dataset_test:\n","    x3 = tf.reshape(x3, (-1, 277, len(postag_label)))\n","    logit = model(\n","                encoder_inputs = x1,\n","                encoder_attention_mask = x2,\n","                postag = x3,\n","                encoder_token_type_id = None,\n","                head_mask = None,\n","                decoder_inputs = x4,\n","                decoder_attention_mask = x5,\n","                decoder_token_type_id = None,\n","    )\n","    start_pred.extend(np.argmax(logit[0].numpy(), axis = -1).tolist())\n","    end_pred.extend(np.argmax(logit[1].numpy(), axis = -1).tolist())\n","\n","    start_true.extend(y[:, 0].numpy().tolist())\n","    end_true.extend(y[:, 1].numpy().tolist())"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"2RceTJpbfECW","executionInfo":{"status":"ok","timestamp":1653645501251,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["from sklearn.metrics import f1_score"]},{"cell_type":"code","execution_count":54,"metadata":{"id":"T0bdUUIGfkHS","executionInfo":{"status":"ok","timestamp":1653645501252,"user_tz":-420,"elapsed":19,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e944d977-9f86-44d7-d621-4125e384c18a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7371509579330184"]},"metadata":{},"execution_count":54}],"source":["start_f1_score = f1_score(start_true, start_pred, average='weighted')\n","end_f1_score = f1_score(end_true, end_pred, average='weighted')\n","f1_sc = (start_f1_score+end_f1_score)/2\n","f1_sc"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"fDdH3Tqjf0s-","executionInfo":{"status":"ok","timestamp":1653645501252,"user_tz":-420,"elapsed":13,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":["em = []\n","for i in range(len(start_pred)):\n","    if start_pred[i] == start_true[i] and end_pred[i] == end_true[i]:\n","        em.append(1)\n","    else:\n","        em.append(0)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"pPukzifwifxA","executionInfo":{"status":"ok","timestamp":1653645501253,"user_tz":-420,"elapsed":14,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b636d39b-1888-46db-fbe2-c8d17cbe4c78"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.725"]},"metadata":{},"execution_count":56}],"source":["np.mean(em)"]},{"cell_type":"code","execution_count":56,"metadata":{"id":"Ir4hRtq6kQek","executionInfo":{"status":"ok","timestamp":1653645501253,"user_tz":-420,"elapsed":10,"user":{"displayName":"Văn Nghiêm","userId":"03593021723549294443"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"roberta_weight.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}